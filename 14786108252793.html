<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Hadoop搭建实例 - Zhan's Blog
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="Zhan's Blog" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:swuzjb.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="aboutMe.html">RESUME</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; Zhan's Blog</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="iOS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html">iOS学习笔记</a></li>
        
            <li><a href="Java.html">Java</a></li>
        
            <li><a href="%E8%AF%BE%E7%A8%8B%E7%9B%B8%E5%85%B3.html">课程相关</a></li>
        
            <li><a href="%E7%AE%97%E6%B3%95-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html">算法-数据结构</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>Hadoop搭建实例</h1>
     
        <div class="read-more clearfix">
          <span class="date">2016/11/8</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='%E8%AF%BE%E7%A8%8B%E7%9B%B8%E5%85%B3.html'>课程相关</a></span>
           
         
          <span class="comments">
            

            
              &nbsp;<a  class="ds-thread-count" data-thread-key="14786108252793.html" data-count-type="comments" href="14786108252793.html#ds-thread"></a>
            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <blockquote>
<p>本次课程要求自主搭建Hadoop集群环境，并进行MapReduce作业操作<br/>
本文以统计知乎用户地域分布情况为例进行统计展示</p>
</blockquote>

<h2 id="toc_0">数据获取与格式说明</h2>

<h3 id="toc_1">数据获取</h3>

<p>实验数据采用爬虫方式从知乎进行爬取，并保存进入数据库，总数据量3383054条。为了后续处理方便，我们将数据从数据库中倒成csv文件进行存储。<br/>
数据爬取代码：<a href="https://github.com/wycm/mycrawler">知乎爬虫</a></p>

<h3 id="toc_2">数据格式</h3>

<p>导出的数据格式为：<code>id,name,headline,gender,school,major,address,industry,company,job</code><br/>
<img src="media/14786108252793/14786149854526.jpg" alt="" class="mw_img_center" style="display: block; clear:both; margin: 0 auto;"/></p>

<h2 id="toc_3">Hadoop集群搭建</h2>

<p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。<br/>
本次课程实例基于ubuntu12.04、jdk1.8.111、hadoop2.7.3进行说明，其中ubuntu服务器以虚拟机的形式搭建。</p>

<ol>
<li><p>ubuntu虚拟机搭建</p>

<p>虚拟机创建的步骤在本文中不加以介绍，如有需要请自行百度。ps.为了简便操作，我们可以先创建并配置一台虚拟机然后进行克隆。为了简便操作，可以使用<code>sudo apt-get install ubuntu-desktop</code>安装ubuntu的图形操作界面。</p></li>
<li><p>建立软件目录</p>

<p>为了后续更好的管理我们按照的软件。我们使用mkdir命令，建立软件的安装目录。命令：<code>sudo mkdir /usr/soft</code></p></li>
<li><p>jdk的安装与环境变量设置</p>

<ol>
<li>首先我们从Oracle的官网上下载jdk的压缩文件。下载地址：<a href="http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jdk-8u111-linux-x64.tar.gz">jdk</a>;</li>
<li>使用<code>tar -xzvf 文件名</code>对安装包进行解压;</li>
<li>将解压后的文件夹移至上一步我们建立的软件安装目录。<code>mv jdk1.8.0_111/ /usr/soft</code></li>
<li><p>设置java所需要的环境变量:</p>

<ol>
<li>打开配置文件 <code>sudo vi /etc/profile</code>；</li>
<li>在配置文件中加入<code>export JAVA_HOME=&quot;/usr/soft/jdk1.8.0_111&quot;</code>；</li>
<li>在配置文件中加入<code>export PATH=&quot;$PATH:$JAVA_HOME/bin&quot;</code>；</li>
<li>保存配置文件退出；</li>
<li>使用source命令让配置文件生效，<code>source /etc/profile</code></li>
</ol></li>
<li><p>调用<code>javac -version</code>命令，检查配置是否生效,安装是否成功。</p></li>
</ol></li>
<li><p>Hadoop的安装与环境变量设置</p>

<ol>
<li>从Apache Hadoop网站上下载对应的Hadoop安装包。下载地址：<a href="http://mirrors.cnnic.cn/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz">Hadoop2.7.3</a>；</li>
<li>使用<code>tar -xzvf 文件名</code>对安装包进行解压;</li>
<li>将解压后的文件夹移至上一步我们建立的软件安装目录。<code>mv Hadoop-2.7.3 /usr/soft</code></li>
<li>打开配置文件 <code>sudo vi /etc/profile</code>；</li>
<li>在配置文件中加入<code>export PATH=&quot;$PATH:$JAVA_HOME/bin:/usr/soft/hadoop-2.7.3/bin:/usr/soft/hadoop-2.7.3/sbin&quot;</code>；</li>
<li>保存配置文件退出；</li>
<li>使用source命令让配置文件生效，<code>source /etc/profile</code></li>
<li>调用<code>Hadoop version</code>命令，检查配置是否生效,安装是否成功。</li>
</ol></li>
<li><p>SSH免密码登录配置</p>

<ol>
<li>使用<code>sudo apt-get install ssh</code>安装完整的ssh客户端；</li>
<li>使用<code>ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa</code>生成公私钥；</li>
<li>使用<code>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code>将公钥复制；</li>
<li>使用<code>ssh localhost</code>命令检验是否可以免密码登录系统。</li>
</ol></li>
<li><p>修改服务器的名称</p>

<ol>
<li>使用<code>sudo vi /etc/hostname</code>,修改服务器的名称</li>
<li>重启服务器使配置生效</li>
</ol></li>
<li><p>配置Hadoop配置文件</p>

<p>Hadoop的配置文件位于其安装目录下的etc/hadoop/目录下</p>

<ol>
<li><p>修改yarn-site.xml，内容如下（master代表主服务器名）：</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://master/&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;~/hadoop/data&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>修改hdfs-site.xml，内容如下:</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>修改mapred-site.xml（此文件需要从mapred-site.xml.template复制），内容如下：</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>修改yarn-site.xml,内容如下：</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;master&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;master:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;master:8030&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>修改slaves文件，将附属机主机名添加入内，每行一个，样例为:</p>

<pre><code class="language-xml">s1
s3
</code></pre></li>
</ol></li>
<li><p>克隆宿主机，配置hosts文件</p>

<ol>
<li>使用VM的克隆功能，克隆虚拟机，并依次修改主机名</li>
<li><p>根据实际IP修改各个机器的hosts文件，ip查看可以使用<code>ifconfig</code>命令，样例如下：</p>

<pre><code>127.0.0.1  localhost    
10.104.234.203  master
182.254.216.245 s1
123.207.252.11 s2
123.207.24.98 s3
</code></pre></li>
</ol></li>
<li><p>格式化HDFS文件系统，执行<code>hdfs namenode -format</code>命令，对HDFS进行格式化。</p></li>
<li><p>启动Hadoop集群</p>

<ol>
<li>启动文件系统,<code>start-dfs.sh</code>;</li>
<li>启动yarn，<code>start-yarn.sh</code>;</li>
<li>可以使用<code>jps</code>命令，检查各个服务的启动情况</li>
</ol></li>
</ol>

<h2 id="toc_4">统计程序的编写与运行</h2>

<p>本次实验所用的MapReduce程序采用Maven的方式进行构建，具体操作可以参考文章：<a href="http://www.cnblogs.com/Leo_wl/p/4862820.html">Maven构建Hadoop工程</a></p>

<ol>
<li><p>编写Mapper类，本次我们实现的功能从原理上与Hadoop自带的WordCount实验非常相似。</p>

<pre><code class="language-java">package com.swu.count;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class CountMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    @Override
    protected void map(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)
            throws IOException, InterruptedException {
        // 获取每一行数据，并以逗号为基准进行分割
        String[] data = value.toString().split(&quot;,&quot;);
        // 设置word的key为地址信息
        word.set(data[5]);
        // 设置value为1
        context.write(word, one);
    }

}
</code></pre></li>
<li><p>编写Reducer类。</p>

<pre><code class="language-java">package com.swu.count;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class CountReduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();
    private Text keyEx = new Text();

    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,
            Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context) throws IOException, InterruptedException {
        int sum = 0;
        // 遍历value相加
        for (IntWritable val : values) {
            sum += val.get();
        }
        // 返回新的key-value
        result.set(sum);
        keyEx.set(key);
        context.write(keyEx, result);
    }
}
</code></pre></li>
<li><p>编写Comparator类，用于第二次作业的排序。</p>

<pre><code class="language-java">package com.swu.count;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.WritableComparable;

public class CountComparator extends IntWritable.Comparator {

    @Override
    public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) {
        // TODO Auto-generated method stub
        return -super.compare(b1, s1, l1, b2, s2, l2);
    }
    public int compare(WritableComparable a, WritableComparable b) {
        // TODO Auto-generated method stub
        return -super.compare(a, b);
    }
}
</code></pre></li>
<li><p>编写主方法。</p>

<pre><code class="language-java">package com.swu.count;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import java.util.Random;

import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
import org.apache.hadoop.mapreduce.lib.map.InverseMapper;

public class Main {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        if (otherArgs.length != 2) {
            System.err.println(&quot;Usage: zhihuCount &lt;in&gt; &lt;out&gt;&quot;);
            System.exit(2);
        }
        Path tempDir = new Path(&quot;wordcount-temp-&quot; + Integer.toString(new Random().nextInt(Integer.MAX_VALUE))); // 定义一个临时目录

        Job job = new Job(conf, &quot;zhihuCount&quot;);
        job.setJarByClass(Main.class);
        try {
            job.setMapperClass(CountMapper.class);
            job.setCombinerClass(CountReduce.class);
            job.setReducerClass(CountReduce.class);

            job.setOutputKeyClass(Text.class);
            job.setOutputValueClass(IntWritable.class);

            FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
            FileOutputFormat.setOutputPath(job, tempDir);
            // 先将词频统计任务的输出结果写到临时目录中,下一个排序任务以临时目录为输入目录。
            job.setOutputFormatClass(SequenceFileOutputFormat.class);
            if (job.waitForCompletion(true)) {
                Job sortJob = new Job(conf, &quot;sort&quot;);
                sortJob.setJarByClass(Main.class);
                FileInputFormat.addInputPath(sortJob, tempDir);
                sortJob.setInputFormatClass(SequenceFileInputFormat.class);

                /* InverseMapper由hadoop库提供，作用是实现map()之后的数据对的key和value交换 */
                sortJob.setMapperClass(InverseMapper.class);
                /* 将 Reducer 的个数限定为1, 最终输出的结果文件就是一个。 */
                sortJob.setNumReduceTasks(1);
                FileOutputFormat.setOutputPath(sortJob, new Path(otherArgs[1]));

                sortJob.setOutputKeyClass(IntWritable.class);
                sortJob.setOutputValueClass(Text.class);
                /*
                 * Hadoop 默认对 IntWritable 按升序排序，而我们需要的是按降序排列。 因此我们实现了一个
                 * IntWritableDecreasingComparator 类, 并指定使用这个自定义的 Comparator
                 * 类对输出结果中的 key (词频)进行排序
                 */
                sortJob.setSortComparatorClass(CountComparator.class);

                System.exit(sortJob.waitForCompletion(true) ? 0 : 1);
            }
        } finally {
            FileSystem.get(conf).deleteOnExit(tempDir);
        }
    }
}
</code></pre></li>
<li><p>将写好的程序编译为jar包(注意指定Main方法)，上传至服务器。</p></li>
<li><p>执行<code>hadoop jar XXX.jar /inputFile /outputFile</code>，执行作业。</p></li>
</ol>

<h2 id="toc_5">结果展示与说明</h2>

<p>上述作业结束后，我们就可以通过查询输出文件得到我们的统计结果。本次实验统计结果如下：<br/>
<img src="media/14786108252793/14787497512630.jpg" alt=""/><br/>
输出文件如下：<br/>
<img src="media/14786108252793/14787497741393.jpg" alt=""/></p>

<h2 id="toc_6">相关代码</h2>

<p>本次实验相关代码和所用的数据资料，均已上传至码云仓库（OSChina git）地址为：<a href="https://git.oschina.net/cobber/HadoopPractice">HadoopPractice</a></p>

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="14814626217350.html" 
          title="Previous Post: HTTPS技术简要介绍">&laquo; HTTPS技术简要介绍</a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="14773646522828.html" 
          title="Next Post: 网易Java Web微专业Spring-Web框架单元作业">网易Java Web微专业Spring-Web框架单元作业 &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          

          

          
              <div class="ds-thread" data-thread-key="14786108252793.html" data-url="http://swuzjb.github.io/14786108252793.html" data-title="Hadoop搭建实例"></div>
          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="asset/img/icon.jpg" /></div>
            
                <h1>Zhan's Blog</h1>
                <div class="site-des">展镜博的个人博客</div>
                <div class="social">









<a class="github" target="_blank" href="https://github.com/swuzjb" title="GitHub">GitHub</a>
<a class="email" href="mailto:412008196@qq.com" title="Email">Email</a>
  <a class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>
              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="iOS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html"><strong>iOS学习笔记</strong></a>
        
            <a href="Java.html"><strong>Java</strong></a>
        
            <a href="%E8%AF%BE%E7%A8%8B%E7%9B%B8%E5%85%B3.html"><strong>课程相关</strong></a>
        
            <a href="%E7%AE%97%E6%B3%95-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html"><strong>算法-数据结构</strong></a>
         
        </p>


                </div>
              </div>
              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>BookList</h2>
                </div>
                <div class="side-content">

                <p class="cat-list">
                
                    <a href="bookList.html"><strong>待读书单</strong></a>
                
                </p>


                </div>
              </div>
              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="14892373699810.html">设计模式-简单工厂模式</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14892189846734.html">设计模式-装饰模式</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14892030475974.html">设计模式-观察者模式</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14891973906960.html">剑指Offer-递归和循环</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14891427018088.html">设计模式-策略模式</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
                <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>FRIEND LINKS</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
                  <li class="post">
                    <a href="https://guxinyan.github.io">顾鑫燕的博客</a>
                    
                  </li>
                  <li class="post">
                    <a href="http://ranchu.win">CD'S Blog</a>
                  </li>
                  <li class="post">
                    <a href="https://hran.me">Hran's Blog</a>
                  </li>
          </ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2016 swuzjb
  </div>
</div>

        </section>
      </div>
    </div>

  


<script type="text/javascript">
var duoshuoQuery = {short_name:'zhanjingbo'};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?0fb9ecff8c9a2c820ce81c18ff77c1e8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  </body>
</html>
